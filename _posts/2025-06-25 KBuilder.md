---
title: "Kbuilder"
date: "2025-06-25"
---

AI Coding 是 AGI 的关键能力之一，而 AGI 则是 AI Coding 能力通用化和自我演化的最终形态。一个好的 AI Coding 工具，应该能：

- 阅读和理解源代码（“看懂世界”）
- 修改现有程序（“改造世界”）
- 编写新的功能（“创造新的工具”）
- 自我更新

## AI Coding 的经典瓶颈

1. 长上下文理解能力
2. 多轮任务连续性（某个角度看是问题一的延续）
3. 验证功能正确性（和 UI 美观等）
4. 自我确定进化的方向

## 设计目标

借助 Kotlin Multiplatform 的特性，此库提供 web/wasm, desktop/jvm, desktop/native 三种编译目标（也许未来应该支持 mobile/android/ios），最大限度地让它能在多种平台场景下使用。

## MVP

如果只提供以下两个条件
- 文件系统(网络 I/O, 本地文件 I/O) 
- 执行任意 shell 命令

那么理论上，人类可以根据这个创造出所需要的工具并持续地改进此工具。并以 PDCA 环持续地改进工具。人类会累，因此需要定期休息，对应 AI 则是 API 可能会有限频（可以理解电要省着用），需要写个脚本定期执行，定期检查当前项目进展，如果有问题，修复问题，如果问题都解决了，针对当前特性思考后续plan （或基于已有 plan 继续进行开发）。 人类与 AI 都会遇到这样一个终级问题：我是谁，我在哪，我要去哪。 幸运的是，AI （也许）不需要思考这个，人类会给它定义目标，边界。

- Plan 阶段：为了避免 AI 走向错误的方向，或者 AI 走向人类无法理解的方向，我们需要在 AI 开始工作前，review 它的工作计划。
- Do 阶段：如有必要，AI 可在发现自己处理同一问题耗时过长时请求人类介入
- Check/Adjust 阶段：每天也应 review 它的工作成果，并基于此提出指导意见。这一步，同样可以让 AI 先自行 review 和给出改进意见，然后人类再 review AI 的 review 结果与改进意见。

**任意 shell 命令**太危险了，因此需要限制在某个目录下执行，或者限制在某个文件系统下执行。也许只需提供读写目录文件功能？但如果有构建系统，那必然需要 shell 命令。不如，只提供某种系统下的构建命令，比如，如果我需要用 gradle 则只提供 gradle 命令，如果我需要用 npm 则只提供 npm 命令。这样就即避免任意 shell 命令的危险，也可约束 LLM 的执行范围。

### 如何自我更新

自我更新是个危险动作，可以考虑三个不同阶段用三种不同的方案：

- 早期 Demo：修改代码->生成新可执行文件替换旧的->下一循环使用新可执行文件
- 中期：增加守护者角色，守护者来负责以下流程：定时器触发 -> 1. 检查工作者状态 -> 2. 为工作者定义新目标 -> 3. 读取工作者源码 -> 4. 调用AI生成新代码 -> 5. 编译并测试工作者新代码 -> 6. 若成功，则停止旧工作者，启动新工作者

----

```markdown
你是初代的 AI 编程工具 KB-v0。你是一个 AI Coding Assistant，你旨在为人类提供
```


----

## 一些零碎的思考

### 幻觉

人类的`幻觉`与 AI 如出一辙，比如，小学生做作业时，这道题 `请在括号内填 >,=,< ： 1 + 2 ( ) 2` 选择了 `=` 而非 `>`。又比如另一个笑话：`买10 个西红杮，如果见到西瓜就买一个`，结果只买了一个西红杮回来(因为看到了西瓜）。

我们时常说 LLM 并不会*真正*地思考，它只是按我们训练出来的模式来生成文本。但这里有一个定义未清的点：**什么是真正的思考**，人类又是如何进行思考的？


### 上下文遗忘

### 专家盲点(知识的诅咒)

**当一个人掌握了某项知识后，就很难想象或理解“没有掌握这项知识时”是什么状态或感受**。专家和非专家交流时，会高估对方的理解能力，导致专家在解释时使用了过多的专业术语或假设对方已经了解某些背景知识，从而使得非专家难以理解。