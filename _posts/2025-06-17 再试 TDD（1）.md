---
title: "再试 Tdd（1）"
date: "2025-06-17"
---

这个“再”没有前文，因为之前的一次尝试并没有写总结出来，之前得到的结论是，TDD 看起来很美：它可以**让人类从“测试”这种无聊的角色中解放出来，从而让 AI 真正地实现从实现到验收的自动化**。但实际上还有很多路要走，最典型的一个问题是：谁来保证 AI 生成的单测是对的。

当时还是Claude 3.7 ，现在 Claude 4.0 发布了，而且 Vibe coding 有一 Augment 这个长上下文的利器，也许问题得到了改进，今天尝试一下。

---
## 尝试一

本次尝试，AI 并没严格按 TDD 的步骤来，导致在第二次对话时，生成的项目，单测是失败状态的。
```markdown
请为 AI Coding CLI 产品创建一个新的 Kotlin Gradle 项目。

1. 初始化项目结构，确保包含 Kotlin 支持和 JUnit 5 依赖项以进行测试驱动开发 (TDD)。
2. 实现一个基础的命令行参数解析功能，能够识别不带任何参数的程序启动。
3. 以 TDD 方式开发第一个功能：当用户在命令行输入 `--version` 参数时，程序应在控制台打印预定义的版本号（例如 "0.1.0"）。请确保先编写相应的单元测试。
4. 以 TDD 方式开发第二个功能：当用户在命令行输入 `--help` 参数时，程序应在控制台打印一个简单的帮助信息，说明程序用途和可用的基本命令。请确保先编写相应的单元测试。
```
提交给 Augment，完成了。但从过程看，它并没有按 TDD 要求进行，而是先写了实现再写单测，不过我们先不做纠正继续当前的方式，因为看起来 AI 尽管没按 TDD 原教旨来，但还是能完成任务并提供了充足的单测。完成了初始化后，进一步要求生成：

```markdown
基于已完成的 CLI 基础框架，请继续使用 TDD 方式扩展 AI Coding CLI 工具，添加 AI 服务集成功能。  
  
**功能要求：**  
  
1. **AI 服务提供商抽象层**  
- 设计统一的 AI 服务接口，支持多种 AI 提供商（OpenAI、Claude、Gemini 等）  
- 实现服务提供商的动态加载和切换机制  
- 支持不同模型的参数配置（temperature、max_tokens 等）  
  
2. **API 调用和错误处理**  
- 实现 HTTP 客户端封装，支持异步调用  
- 完善的错误处理机制（网络错误、API 限流、认证失败等）  
- 重试策略和超时控制  
- API 密钥管理和安全存储  
  
3. **响应解析和格式化**  
- 统一的响应数据模型  
- 支持流式响应和批量响应  
- 响应内容的格式化和清理（去除多余的标记符号）  
- 响应缓存机制  
  
4. **AI 服务测试命令**  
- 添加 `test-connection` 命令验证 AI 服务连接  
- 添加 `ask` 命令进行简单的 AI 问答测试  
- 实现服务健康检查和状态监控  
  
**验收标准：**  
- 能够成功连接至少一个 AI 服务提供商  
- 所有网络调用都有适当的错误处理和重试机制  
- 配置文件中可以设置多个 AI 服务提供商  
- `test-connection` 和 `ask` 命令能够正常工作  
- 所有新功能都有完整的单元测试和集成测试  
  
**技术提示：**  
- 考虑使用 Ktor 或 OkHttp 作为 HTTP 客户端  
- 使用 Kotlinx.serialization 进行 JSON 序列化  
- 实现适配器模式来统一不同 AI 服务的接口  
  
请继续遵循 TDD 开发模式，先编写测试用例，再实现功能代码。
```
这一轮生成了 2223 行代码，使用了 2 轮 Augment 对话。但它生成的单测会部分运行失败，显然 Augment 并没有把所有单测都通过做为一个验收点，从执行记录就能看出来：
![[Pasted image 20250617134235.png]]
测试失败的了，分析完原因，然后就没有然后了。最后，它的总结里还有这么一段描述：

![[Pasted image 20250617132727.png]]

显然，幻觉从这里开始产生了。我相信，**如果我继续在这个会话中迭代，这里言行互相矛盾的历史会话将导致后续越来越不可控**，此次尝试到此为止。

## 尝试二

> TDD 的步骤对 AI 来说**也许并不重要**，TDD 要规避的是人类的弱点，确保人类每次都聚焦并完成一个简单的任务上，对 AI 来说，如果这样做，将会浪费大量的 token。但从另一个角度看，我的**初衷是让 AI 使用 TDD 的方式，让所有开发任务和需求可追溯，并确保每个功能点都有单测覆盖，如果没了这个，项目后期将完全不可控**。

上一迭代发现的问题：

- Augment 没有严格按 Red-Green-Refactor 的方式来，而是先写代码再写测试
- Augment 在修复代码逻辑后，使用了自己的验证方式而不是通过单测来验证
- Augment 在生成代码时，未能确保所有单测都通过
- 同一会话中进行多次迭代，导致历史会话的影响越来越大，容易产生幻觉，要设法让会话各自独立

以上问题的产生极可能是其系统 Prompt 约束所导致，因此，需要我们在 Prompt 中明确要求其按 TDD 的方式来完成任务。


添加 Augment User Guidelines:

```markdown
- 严格按 TDD 的开发顺序执行，不要使用执行单测以外的验证工具，并且在每个 Green-Refactor 步骤里，必须始终保证所有单测都不被破坏。
- 在 Red-Green-Refactor 三个生命周期的每一步完成时，都提交到 Git 仓库中
- 以小步修改小步验证的方式进行，避免大型破坏性的修改，如果任务过大，请按此粒度拆解并提供 ATDD 测试，然后再按 TDD 的方式执行各小任务。
```
按上面的第一条 Prompt 再次让 Augment 来执行，看起来它已经按 TDD 的方式来执行了：

![[Pasted image 20250617152422.png]]

还有点问题，如下，修改配置引入依赖项也被当成 Red 的步骤来提交：
![[6de6cd9d-054f-4032-b35f-c86fc85cc08c.png]]
它连写一个 `data class`都要写测试，这犯了很多刚接触单测的新手的错误，去测一些无谓的 getter/setter 函数以及测试一些三方库的内部行为：
```kotlin
@Test  
fun `should create AI request with required fields`() {  
    // Arrange & Act  
    val request = AiRequest(  
        messages = listOf(  
            AiMessage(role = MessageRole.USER, content = "Hello, AI!")  
        ),  
        model = "gpt-3.5-turbo",  
        temperature = 0.7f,  
        maxTokens = 1000  
    )  
  
    // Assert  
    assertEquals(1, request.messages.size)  
    assertEquals("Hello, AI!", request.messages[0].content)  
    assertEquals(MessageRole.USER, request.messages[0].role)  
    assertEquals("gpt-3.5-turbo", request.model)  
    assertEquals(0.7f, request.temperature)  
    assertEquals(1000, request.maxTokens)  
}

@Test
fun `should make successful GET request`() = runTest {
	// Arrange
	val mockEngine = MockEngine { request ->
		respond(
			content = ByteReadChannel("""{"message": "success"}"""),
			status = HttpStatusCode.OK,
			headers = headersOf(HttpHeaders.ContentType, "application/json")
		)
	}
	val httpClient = AiHttpClient(mockEngine)

	// Act
	val response = httpClient.get("https://api.example.com/test")

	// Assert
	assertEquals(HttpStatusCode.OK, response.status)
	assertEquals("""{"message": "success"}""", response.body)
	assertEquals("application/json", response.headers["Content-Type"])
}
```

显然，AI 的训练数据里有大量这种反模式的测试代码存在，需要告诉他们应该测什么，不应该测什么：

```markdown
**测试策略要求：** 
1. 识别核心业务逻辑，忽略简单的数据传递 
2. 忽略第三方库自身的行为
**必须包含的测试场景：** 
- ✅ 输入验证和异常处理
- ✅ 业务规则的正确执行
- ✅ 边界条件和极端情况
- ✅ 状态变化和副作用
**避免的无价值测试：**
- ❌ 纯字段赋值验证
- ❌ 编译器已保证的类型安全
- ❌ 框架自动生成的方法
```
接下来生成的质量就高很多了，不过，现在 Augment 响应开始迟顿了
![[Pasted image 20250617171434.png]]
也许真的到时间**下班**了！明天再继续吧。