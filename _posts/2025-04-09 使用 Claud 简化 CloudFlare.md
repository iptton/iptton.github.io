

> MCP 在一定程度上并不是一个创新，只是一个*可能*未来大家都承认的事实标准。本文尝试从一个可实操的场景上手理解什么是 MCP，本文所提到的工具需科学上网。

Cloudflare 较早就提供了 [MCP 支持](https://github.com/cloudflare/mcp-server-cloudflare)，结合 `cursor`/`windsurf`等工具，也许能实现从客户端到后台的一站式服务？

## Cloudflare MCP 提供的工具




## 什么样的大语言模型支持 MCP ?

MCP 并没有改变 LLM 的工作方式，LLM 依然是一个文本生成工具，可以认为 MCP 本身和大模型并没任何关系。

LLM 的工作方式是，根据上文，生成下文。在一轮使用 MCP 的对话中有三个步骤：

- MCP 组织上文告诉大模型，可以用什么样的工具能解决用户的问题。
- 大模型分析用户的问题，解析出用户的意图，如果发现所提供的工具能解决用户问题，或所提供的能力能提供解决用户问题所需要的信息。返回需要调用的工具告诉客户端。
- 客户端调用工具，获取结果，返回给大模型。
- 大模型分析工具返回的结果，生成最终的回答。（如果还有后续问题，返回到第一步）

在上述步骤中，大模型的指令遵循能力是关键，大模型本身并不需要知道 MCP 的存在。

## 遇到的问题

- Claude Desktop 的 mcp server config 的修改需要重启客户端才能生效。

## MCP 的局限性

- 由于对工具的描述是自然语言，极其自由，这意味着不同的 server 或同一 server 不同的工具可能都会命中用户的意图，从而 LLM 不一定能正确调用你需要的工具。
- 当工具极多时，prompt 上下文的长度会变得很长，可能会影响 LLM 的性能。
